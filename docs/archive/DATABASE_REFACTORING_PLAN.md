# üèóÔ∏è PIANO DI REFACTORING COMPLETO - DATABASE & DATA ACCESS LAYER

**Progetto**: CRM Immobiliare
**Data**: 2025-11-10
**Versione**: 1.0
**Status**: In Revisione

---

## üìã EXECUTIVE SUMMARY

### Situazione Attuale
Il database √® **funzionale** ma presenta **criticit√† strutturali** che impediscono un deployment sicuro in produzione:

- ‚úÖ **Schema ben progettato**: 18 modelli, 105 indici, relazioni ottimizzate
- ‚ùå **Duplicazione critica**: Prisma (TypeScript) vs SQLAlchemy (Python) non sincronizzati
- ‚ùå **No migrations formali**: Rischio deployment elevato
- ‚ùå **No backup strategy**: Rischio data loss
- ‚ö†Ô∏è **Pattern inconsistenti**: Mix di approcci tra frontend/backend

### Obiettivi del Refactoring

1. **Affidabilit√†**: Sistema di migrations, backup automatici, transazioni atomiche
2. **Accessibilit√†**: API uniforme, service layer, caching intelligente
3. **Modularit√†**: Repository pattern, dependency injection, layer separation
4. **Efficacia**: Query optimization, monitoring, validation layer

### Risultato Atteso

```
BEFORE                          AFTER
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Schema drift risk: HIGH    ‚Üí    Automated sync: 100%
Deployment risk: CRITICAL  ‚Üí    Migration system: SAFE
Query patterns: 6 different ‚Üí   Unified service layer
Validation: 40% coverage   ‚Üí    100% coverage
No monitoring              ‚Üí    Full observability
No caching                 ‚Üí    Redis + in-memory
Direct DB access: 38 files ‚Üí   Service layer: 8 classes
```

**Effort Totale**: 4 settimane (1 sviluppatore)
**ROI**: Riduzione maintenance -70%, deployment time -90%, bug rate -80%

---

## üéØ STRATEGIA DI REFACTORING

### Approccio: Incrementale e Non-Blocking

```
Phase 1 (Critical)    ‚Üí  Phase 2 (High)     ‚Üí  Phase 3 (Medium)   ‚Üí  Phase 4 (Long-term)
    Week 1                 Week 2                Week 3                Week 4+

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇMigrations‚îÇ          ‚îÇ Service ‚îÇ          ‚îÇRepository‚îÇ          ‚îÇMigration‚îÇ
    ‚îÇ  System ‚îÇ    ‚Üí     ‚îÇ  Layer  ‚îÇ    ‚Üí     ‚îÇ Pattern  ‚îÇ    ‚Üí     ‚îÇ   to    ‚îÇ
    ‚îÇ Backups ‚îÇ          ‚îÇValidation‚îÇ          ‚îÇ Caching  ‚îÇ          ‚îÇ  Postgres‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Principi**:
- ‚úÖ **Zero downtime**: Refactoring incrementale
- ‚úÖ **Backward compatible**: Vecchio e nuovo coesistono
- ‚úÖ **Test-driven**: Test per ogni modulo
- ‚úÖ **Documentation-first**: Ogni change documentato

---

## üìä PROBLEMI IDENTIFICATI (Prioritized)

### üî¥ CRITICAL - Blockers per Produzione

| ID | Problema | Impact | Effort | Priority |
|----|----------|--------|--------|----------|
| C1 | Duplicazione Prisma/SQLAlchemy | Schema drift, bug | 3d | P0 |
| C2 | No migration system | Deploy risk | 1d | P0 |
| C3 | No backup strategy | Data loss risk | 2d | P0 |
| C4 | DATABASE_URL configuration hell | Setup errors | 4h | P0 |

### üü° HIGH - Urgent Refactoring

| ID | Problema | Impact | Effort | Priority |
|----|----------|--------|--------|----------|
| H1 | No validation layer (Python) | Data integrity | 1d | P1 |
| H2 | Transaction handling missing | Race conditions | 1d | P1 |
| H3 | No service layer | Code duplication | 2d | P1 |
| H4 | Direct DB access (38 files) | Maintenance burden | 3d | P1 |

### üü¢ MEDIUM - Best Practices

| ID | Problema | Impact | Effort | Priority |
|----|----------|--------|--------|----------|
| M1 | No caching layer | Performance | 2d | P2 |
| M2 | No database monitoring | Debugging difficulty | 1d | P2 |
| M3 | Query patterns inconsistenti | Code quality | 2d | P2 |
| M4 | No soft delete | Data recovery | 1d | P2 |

### üîµ LOW - Nice to Have

| ID | Problema | Impact | Effort | Priority |
|----|----------|--------|--------|----------|
| L1 | No full-text search | Search quality | 3d | P3 |
| L2 | SQLite limitations | Scalability | 1w | P3 |
| L3 | No connection pooling monitor | Ops visibility | 1d | P3 |

---

## üöÄ PHASE 1: CRITICAL FIXES (Week 1)

**Obiettivo**: Rendere il sistema production-ready eliminando rischi critici
**Durata**: 5 giorni
**Effort**: 40 ore

### 1.1 Sistema di Migrations Formale (C2) - 1 giorno

#### Problema
```bash
# Attuale: Schema changes non tracciati
$ npx prisma db push  # ‚ùå No history, no rollback
```

#### Soluzione
```bash
# Nuovo workflow con migrations
$ npx prisma migrate dev --name add_user_preferences
‚úì Migration created: 20251110120000_add_user_preferences
‚úì Migration applied
‚úì Generated Prisma Client
```

#### Task List
- [ ] Inizializzare Prisma migrations
  ```bash
  cd database/prisma
  npx prisma migrate dev --name initial_schema
  ```
- [ ] Creare migration baseline da schema attuale
- [ ] Documentare workflow migrations in README
- [ ] Configurare CI/CD per validare migrations
- [ ] Creare script `validate-migrations.sh`

#### File da Creare
```
database/prisma/
‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îú‚îÄ‚îÄ 20251110_initial_schema/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migration.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ migration_lock.toml
‚îî‚îÄ‚îÄ MIGRATIONS.md  (workflow documentation)
```

#### Test di Validazione
```typescript
// tests/database/migrations.test.ts
describe('Prisma Migrations', () => {
  it('should apply all migrations without errors', async () => {
    await exec('npx prisma migrate deploy');
    // Success
  });

  it('should rollback migration', async () => {
    await exec('npx prisma migrate resolve --rolled-back <migration>');
    // Verify schema reverted
  });
});
```

**Deliverable**: Migration system operativo + documentazione + CI check

---

### 1.2 Strategia di Backup Automatici (C3) - 2 giorni

#### Problema
- Nessun backup automatico
- `seed-map-data.ts` CANCELLA TUTTO senza warning

#### Soluzione: Sistema multi-layer

**Layer 1: Backup Automatici (Prima di Operazioni Pericolose)**

```typescript
// scripts/utils/auto-backup.ts
export async function createBackupBeforeSeed() {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const backupPath = `backups/pre-seed-${timestamp}.db`;

  await fs.copy('database/prisma/dev.db', backupPath);
  console.log(`‚úÖ Backup created: ${backupPath}`);

  return backupPath;
}

// scripts/seed-map-data.ts (MODIFICATO)
async function main() {
  // üõ°Ô∏è BACKUP OBBLIGATORIO
  const backupPath = await createBackupBeforeSeed();

  const confirm = await prompts({
    type: 'confirm',
    name: 'proceed',
    message: `‚ö†Ô∏è  This will DELETE ALL DATA. Backup saved to ${backupPath}. Continue?`,
    initial: false
  });

  if (!confirm.proceed) {
    process.exit(0);
  }

  // Proceed with seed...
}
```

**Layer 2: Backup Schedulati (Development)**

```typescript
// scripts/backup-scheduler.ts
import schedule from 'node-schedule';

// Backup giornaliero alle 2 AM
schedule.scheduleJob('0 2 * * *', async () => {
  const timestamp = new Date().toISOString().split('T')[0];
  await createBackup(`backups/daily-${timestamp}.db`);

  // Keep last 7 days
  await cleanOldBackups(7);
});
```

**Layer 3: Backup Pre-Migration (Production)**

```bash
# scripts/migrate-with-backup.sh
#!/bin/bash
set -e

echo "üõ°Ô∏è  Creating pre-migration backup..."
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_PATH="backups/pre-migration-${TIMESTAMP}.db"

# Copy database
cp database/prisma/dev.db "$BACKUP_PATH"

echo "‚úÖ Backup saved: $BACKUP_PATH"
echo "üîÑ Running migration..."

# Run migration
npx prisma migrate deploy

echo "‚úÖ Migration complete!"
echo "üóëÔ∏è  To rollback: cp $BACKUP_PATH database/prisma/dev.db"
```

**Layer 4: Backup Recovery Scripts**

```typescript
// scripts/restore-backup.ts
import prompts from 'prompts';
import { glob } from 'glob';

async function restoreBackup() {
  // List available backups
  const backups = await glob('backups/*.db');

  const { selectedBackup } = await prompts({
    type: 'select',
    name: 'selectedBackup',
    message: 'Select backup to restore:',
    choices: backups.map(b => ({
      title: `${path.basename(b)} (${formatFileDate(b)})`,
      value: b
    }))
  });

  // Confirm
  const { confirm } = await prompts({
    type: 'confirm',
    name: 'confirm',
    message: `‚ö†Ô∏è  This will OVERWRITE current database. Continue?`,
    initial: false
  });

  if (!confirm) return;

  // Restore
  await fs.copy(selectedBackup, 'database/prisma/dev.db');
  console.log('‚úÖ Database restored!');
}
```

#### Task List
- [ ] Creare directory `backups/` con `.gitignore`
- [ ] Implementare `auto-backup.ts` utility
- [ ] Modificare `seed-map-data.ts` con backup obbligatorio
- [ ] Creare `backup-scheduler.ts` per dev
- [ ] Creare `migrate-with-backup.sh` per production
- [ ] Creare `restore-backup.ts` interactive CLI
- [ ] Documentare backup workflow in `BACKUPS.md`

#### File da Creare
```
/
‚îú‚îÄ‚îÄ backups/
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore  (ignore *.db)
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auto-backup.ts
‚îÇ   ‚îú‚îÄ‚îÄ backup-scheduler.ts
‚îÇ   ‚îú‚îÄ‚îÄ restore-backup.ts
‚îÇ   ‚îî‚îÄ‚îÄ migrate-with-backup.sh
‚îî‚îÄ‚îÄ BACKUPS.md
```

**Deliverable**: Sistema backup completo + recovery scripts + documentazione

---

### 1.3 Unificazione Configurazione DATABASE_URL (C4) - 4 ore

#### Problema
```bash
# 3 modi diversi di specificare DATABASE_URL!
.env.local:          DATABASE_URL="file:./database/prisma/dev.db"
config/.env.global:  DATABASE_URL_PRISMA="file:./dev.db"
config/.env.global:  DATABASE_URL_SQLALCHEMY="sqlite:///../database/prisma/dev.db"
```

#### Soluzione: Single Source of Truth

**File Unico: `database/.env.database`**
```bash
# =============================================================================
# DATABASE CONFIGURATION - SINGLE SOURCE OF TRUTH
# =============================================================================
# This file is THE ONLY place where DATABASE_URL should be defined
# All other configs should import from here
# =============================================================================

# Development (SQLite)
DATABASE_URL="file:./database/prisma/dev.db"

# Test (SQLite in-memory)
TEST_DATABASE_URL="file::memory:?cache=shared"

# Production (PostgreSQL - future)
# DATABASE_URL="postgresql://user:password@localhost:5432/crm_immobiliare"

# =============================================================================
# INTERNAL - Auto-generated paths (DO NOT EDIT)
# =============================================================================
# These are computed from DATABASE_URL above

# For Prisma (TypeScript)
DATABASE_URL_PRISMA="${DATABASE_URL}"

# For SQLAlchemy (Python) - converted format
DATABASE_URL_SQLALCHEMY="sqlite:///./database/prisma/dev.db"

# Absolute path for scripts
DATABASE_ABSOLUTE_PATH="${PWD}/database/prisma/dev.db"
```

**Importare in Altri Config**

```typescript
// frontend/.env
# Import database config
DATABASE_URL="file:./database/prisma/dev.db"

// ai_tools/.env
# Import database config (Python format)
DATABASE_URL="sqlite:///./database/prisma/dev.db"
```

**Helper Script per Validazione**

```typescript
// scripts/validate-database-config.ts
import dotenv from 'dotenv';
import path from 'path';

function validateDatabaseConfig() {
  const configs = [
    '.env.local',
    'database/.env.database',
    'ai_tools/.env'
  ];

  const urls = configs.map(file => {
    const env = dotenv.parse(fs.readFileSync(file));
    return { file, url: env.DATABASE_URL };
  });

  // Check all point to same database
  const dbPaths = urls.map(u => resolveDatabasePath(u.url));
  const unique = [...new Set(dbPaths)];

  if (unique.length > 1) {
    console.error('‚ùå DATABASE_URL mismatch!');
    urls.forEach(u => console.log(`  ${u.file}: ${u.url}`));
    process.exit(1);
  }

  console.log('‚úÖ DATABASE_URL consistent across all configs');
}
```

#### Task List
- [ ] Creare `database/.env.database` come single source
- [ ] Aggiornare tutti `.env*` files per importare da database/.env.database
- [ ] Creare `validate-database-config.ts` script
- [ ] Aggiungere validation a pre-commit hook
- [ ] Documentare in `DATABASE_CONFIG.md`
- [ ] Rimuovere configs duplicate

**Deliverable**: Config unificata + validation script + docs

---

### 1.4 Sincronizzazione Prisma ‚Üî SQLAlchemy (C1) - 3 giorni

#### Problema
- 18 modelli Prisma
- Solo 16 modelli SQLAlchemy
- Mancano: `Tag`, `EntityTag`, `AuditLog`
- Rischio schema drift continuo

#### Soluzione: Automated Sync Pipeline

**Approccio 1: Generate SQLAlchemy from Prisma (RACCOMANDATO)**

```typescript
// scripts/generate-sqlalchemy-models.ts
import { getDMMF } from '@prisma/internals';
import { generateSQLAlchemyModel } from './generators/sqlalchemy-generator';

async function generateSQLAlchemyModels() {
  const dmmf = await getDMMF({ datamodelPath: 'database/prisma/schema.prisma' });

  const models = dmmf.datamodel.models;
  const enums = dmmf.datamodel.enums;

  // Generate Python enums
  const enumsCode = generateEnumsCode(enums);

  // Generate SQLAlchemy models
  const modelsCode = models.map(model =>
    generateSQLAlchemyModel(model)
  ).join('\n\n');

  // Write to file
  const output = `
# ==============================================================================
# AUTO-GENERATED SQLAlchemy Models from Prisma Schema
# ==============================================================================
# DO NOT EDIT MANUALLY - Run: npm run generate:sqlalchemy
# Generated on: ${new Date().toISOString()}
# Source: database/prisma/schema.prisma
# ==============================================================================

from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime, Text, ForeignKey, Enum
from sqlalchemy.orm import relationship
from .database import Base
import enum

${enumsCode}

${modelsCode}
`;

  fs.writeFileSync('database/python/models.py', output);
  console.log('‚úÖ Generated SQLAlchemy models from Prisma schema');
}
```

**Example Generator per un Model**

```typescript
// scripts/generators/sqlalchemy-generator.ts
function generateSQLAlchemyModel(prismaModel: DMMF.Model): string {
  const className = prismaModel.name;
  const tableName = prismaModel.dbName || className.toLowerCase();

  const fields = prismaModel.fields.map(field => {
    if (field.kind === 'object') {
      // Relazione
      return generateRelationship(field);
    } else {
      // Campo normale
      return generateColumn(field);
    }
  }).join('\n  ');

  return `
class ${className}(Base):
    __tablename__ = "${tableName}"

    ${fields}

    def __repr__(self):
        return f"<${className}(id={self.id})>"
`;
}

function generateColumn(field: DMMF.Field): string {
  const sqlType = mapPrismaTypeToSQLAlchemy(field.type);
  const nullable = field.isRequired ? ', nullable=False' : '';
  const primaryKey = field.isId ? ', primary_key=True' : '';
  const autoincrement = field.isId && field.type === 'Int' ? ', autoincrement=True' : '';
  const unique = field.isUnique ? ', unique=True' : '';

  return `${field.name} = Column(${sqlType}${primaryKey}${autoincrement}${nullable}${unique})`;
}

function mapPrismaTypeToSQLAlchemy(prismaType: string): string {
  const typeMap = {
    'String': 'String',
    'Int': 'Integer',
    'Float': 'Float',
    'Boolean': 'Boolean',
    'DateTime': 'DateTime',
    'Json': 'JSON'
  };

  return typeMap[prismaType] || 'String';
}
```

**Approccio 2: Validation Script (Interim Solution)**

```typescript
// scripts/validate-schema-sync.ts
async function validateSchemaSync() {
  const prismaModels = await getPrismaModels();
  const sqlalchemyModels = await getSQLAlchemyModels();

  const issues: Issue[] = [];

  // Check missing models
  const missingInSQL = prismaModels.filter(m =>
    !sqlalchemyModels.find(s => s.name === m.name)
  );

  if (missingInSQL.length > 0) {
    issues.push({
      severity: 'CRITICAL',
      type: 'MISSING_MODEL',
      details: `Missing in SQLAlchemy: ${missingInSQL.map(m => m.name).join(', ')}`
    });
  }

  // Check field consistency
  for (const prismaModel of prismaModels) {
    const sqlModel = sqlalchemyModels.find(s => s.name === prismaModel.name);
    if (!sqlModel) continue;

    for (const prismaField of prismaModel.fields) {
      const sqlField = sqlModel.fields.find(f => f.name === prismaField.name);

      if (!sqlField) {
        issues.push({
          severity: 'HIGH',
          type: 'MISSING_FIELD',
          details: `${prismaModel.name}.${prismaField.name} missing in SQLAlchemy`
        });
      } else if (sqlField.type !== mapPrismaToSQL(prismaField.type)) {
        issues.push({
          severity: 'HIGH',
          type: 'TYPE_MISMATCH',
          details: `${prismaModel.name}.${prismaField.name}: Prisma=${prismaField.type}, SQL=${sqlField.type}`
        });
      }
    }
  }

  // Report
  if (issues.length === 0) {
    console.log('‚úÖ Prisma ‚Üî SQLAlchemy schemas are in sync');
  } else {
    console.error(`‚ùå Found ${issues.length} sync issues:`);
    issues.forEach(issue => {
      console.error(`  [${issue.severity}] ${issue.type}: ${issue.details}`);
    });
    process.exit(1);
  }
}
```

#### Task List
- [ ] Implementare `generate-sqlalchemy-models.ts`
- [ ] Creare type mapping Prisma ‚Üí SQLAlchemy
- [ ] Generare modelli mancanti (Tag, EntityTag, AuditLog)
- [ ] Creare `validate-schema-sync.ts`
- [ ] Aggiungere npm script `npm run generate:sqlalchemy`
- [ ] Aggiungere validation a CI/CD
- [ ] Documentare processo in `SCHEMA_SYNC.md`

#### File da Creare/Modificare
```
scripts/
‚îú‚îÄ‚îÄ generate-sqlalchemy-models.ts     (NEW)
‚îú‚îÄ‚îÄ generators/
‚îÇ   ‚îî‚îÄ‚îÄ sqlalchemy-generator.ts       (NEW)
‚îú‚îÄ‚îÄ validate-schema-sync.ts           (NEW)
‚îî‚îÄ‚îÄ SCHEMA_SYNC.md                    (NEW)

database/python/
‚îî‚îÄ‚îÄ models.py                         (MODIFIED - auto-generated)

package.json
‚îú‚îÄ‚îÄ "generate:sqlalchemy": "tsx scripts/generate-sqlalchemy-models.ts"
‚îî‚îÄ‚îÄ "validate:schema": "tsx scripts/validate-schema-sync.ts"
```

**Deliverable**: Auto-generation pipeline + validation + sync completo

---

### 1.5 Summary Phase 1

**Durata**: 5 giorni
**Effort**: 40 ore
**Costo**: ‚Ç¨3,200 (@ ‚Ç¨80/ora)

**Deliverables**:
- ‚úÖ Sistema migrations Prisma con history
- ‚úÖ Sistema backup automatici (4 layer)
- ‚úÖ Configurazione DATABASE_URL unificata
- ‚úÖ Sync Prisma ‚Üî SQLAlchemy automatizzato
- ‚úÖ CI/CD checks per validazione
- ‚úÖ Documentazione completa

**Success Metrics**:
- [ ] Migrations applicabili senza errori
- [ ] Backup giornalieri automatici
- [ ] Zero config mismatches
- [ ] 100% schema sync Prisma ‚Üî SQLAlchemy
- [ ] CI pipeline green

---

## üîÑ PHASE 2: SERVICE LAYER & VALIDATION (Week 2)

**Obiettivo**: Centralizzare business logic e garantire data integrity
**Durata**: 5 giorni
**Effort**: 40 ore

### 2.1 Service Layer Pattern (H3) - 2 giorni

#### Problema
- 38 file accedono direttamente al database
- Business logic duplicata tra API routes
- Impossibile riutilizzare logica tra frontend/backend

#### Soluzione: Service Layer Architecture

**Struttura Target**:
```
services/
‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îú‚îÄ‚îÄ BaseService.ts           # Abstract base class
‚îÇ   ‚îî‚îÄ‚îÄ ServiceError.ts          # Custom errors
‚îú‚îÄ‚îÄ PropertyService.ts           # Property business logic
‚îú‚îÄ‚îÄ ContactService.ts            # Contact business logic
‚îú‚îÄ‚îÄ RequestService.ts            # Request business logic
‚îú‚îÄ‚îÄ MatchService.ts              # Matching logic
‚îú‚îÄ‚îÄ BuildingService.ts           # Building aggregation
‚îú‚îÄ‚îÄ ActivityService.ts           # Activity tracking
‚îî‚îÄ‚îÄ index.ts                     # Barrel export
```

**Base Service Implementation**:

```typescript
// services/base/BaseService.ts
export abstract class BaseService<T, CreateDTO, UpdateDTO> {
  constructor(protected prisma: PrismaClient) {}

  abstract getModelName(): string;

  async findById(id: string): Promise<T | null> {
    return this.getModel().findUnique({ where: { id } });
  }

  async findMany(filters?: any, pagination?: Pagination): Promise<T[]> {
    return this.getModel().findMany({
      where: filters,
      skip: pagination?.skip,
      take: pagination?.take,
      orderBy: pagination?.orderBy
    });
  }

  async create(data: CreateDTO): Promise<T> {
    // Validation
    await this.validate(data);

    // Create
    return this.getModel().create({ data });
  }

  async update(id: string, data: UpdateDTO): Promise<T> {
    // Validation
    await this.validate(data);

    // Update
    return this.getModel().update({
      where: { id },
      data
    });
  }

  async delete(id: string): Promise<T> {
    // Soft delete se supportato
    if (this.supportsSoftDelete()) {
      return this.softDelete(id);
    }

    return this.getModel().delete({ where: { id } });
  }

  protected abstract validate(data: any): Promise<void>;
  protected abstract supportsSoftDelete(): boolean;

  private getModel() {
    return this.prisma[this.getModelName()];
  }
}
```

**Property Service Implementation**:

```typescript
// services/PropertyService.ts
import { BaseService } from './base/BaseService';
import { Property, Prisma } from '@prisma/client';
import { PropertyCreateDTO, PropertyUpdateDTO, PropertyFilters } from './dto';

export class PropertyService extends BaseService<Property, PropertyCreateDTO, PropertyUpdateDTO> {
  getModelName() {
    return 'property' as const;
  }

  protected async validate(data: any): Promise<void> {
    // Price validation
    if (data.priceSale && data.priceSale < 0) {
      throw new ServiceError('Price cannot be negative');
    }

    // Rooms validation
    if (data.rooms && data.rooms < 0) {
      throw new ServiceError('Rooms cannot be negative');
    }

    // Contract type validation
    if (data.contractType && !['sale', 'rent', 'both'].includes(data.contractType)) {
      throw new ServiceError('Invalid contract type');
    }
  }

  protected supportsSoftDelete(): boolean {
    return true; // Has archivedAt field
  }

  // Custom business logic
  async findAvailableProperties(filters: PropertyFilters) {
    return this.findMany({
      status: 'available',
      ...this.buildFilters(filters)
    });
  }

  async calculateUrgencyScore(propertyId: string): Promise<number> {
    const activities = await this.prisma.activity.findMany({
      where: { propertyId },
      orderBy: { date: 'desc' },
      take: 10
    });

    // Complex urgency calculation
    const score = this.computeUrgency(activities);

    // Update property
    await this.update(propertyId, { urgencyScore: score });

    return score;
  }

  async attachToBuilding(propertyId: string, buildingId: string) {
    return this.prisma.$transaction(async (tx) => {
      // Update property
      const property = await tx.property.update({
        where: { id: propertyId },
        data: { buildingId }
      });

      // Recalculate building stats
      await this.recalculateBuildingStats(buildingId, tx);

      return property;
    });
  }

  private buildFilters(filters: PropertyFilters): Prisma.PropertyWhereInput {
    return {
      contractType: filters.contractType,
      city: filters.city,
      priceSale: {
        gte: filters.priceMin,
        lte: filters.priceMax
      },
      rooms: {
        gte: filters.roomsMin,
        lte: filters.roomsMax
      }
    };
  }

  private computeUrgency(activities: Activity[]): number {
    // Business logic per urgency calculation
    // ...
  }

  private async recalculateBuildingStats(buildingId: string, tx: any) {
    // Aggregate properties di building
    const stats = await tx.property.aggregate({
      where: { buildingId },
      _avg: { urgencyScore: true },
      _count: true
    });

    // Update building
    await tx.building.update({
      where: { id: buildingId },
      data: {
        avgUrgency: stats._avg.urgencyScore,
        totalProperties: stats._count
      }
    });
  }
}
```

**API Route Refactored**:

```typescript
// app/api/properties/route.ts (BEFORE)
export async function GET(request: Request) {
  const properties = await prisma.property.findMany({
    where: { status: 'available' },
    include: { owner: true, building: true }
  });
  return Response.json(properties);
}

// app/api/properties/route.ts (AFTER)
import { PropertyService } from '@/services';

const propertyService = new PropertyService(prisma);

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const filters = parseFilters(searchParams);

  const properties = await propertyService.findAvailableProperties(filters);

  return Response.json(properties);
}

export async function POST(request: Request) {
  const data = await request.json();

  try {
    const property = await propertyService.create(data);
    return Response.json(property, { status: 201 });
  } catch (error) {
    if (error instanceof ServiceError) {
      return Response.json({ error: error.message }, { status: 400 });
    }
    throw error;
  }
}
```

#### Task List
- [ ] Creare `BaseService` abstract class
- [ ] Implementare `PropertyService`
- [ ] Implementare `ContactService`
- [ ] Implementare `RequestService`
- [ ] Implementare `MatchService`
- [ ] Implementare `BuildingService`
- [ ] Implementare `ActivityService`
- [ ] Refactorare API routes per usare services
- [ ] Creare DTO types per ogni service
- [ ] Unit tests per ogni service

**Deliverable**: Service layer completo + API refactored

---

### 2.2 Validation Layer (H1) - 1 giorno

#### Problema
- Frontend: Zod validation ‚úÖ
- Backend Python: **NESSUNA VALIDATION** ‚ùå

#### Soluzione: Pydantic Models

```python
# ai_tools/app/schemas/property_schema.py
from pydantic import BaseModel, Field, validator
from typing import Optional
from enum import Enum

class PropertyType(str, Enum):
    APARTMENT = "apartment"
    HOUSE = "house"
    OFFICE = "office"
    WAREHOUSE = "warehouse"

class PropertyStatus(str, Enum):
    DRAFT = "draft"
    AVAILABLE = "available"
    SOLD = "sold"
    RENTED = "rented"

class PropertyBase(BaseModel):
    title: str = Field(..., min_length=5, max_length=200)
    description: Optional[str] = Field(None, max_length=5000)
    propertyType: PropertyType
    contractType: str = Field(..., regex="^(sale|rent|both)$")

    priceSale: Optional[float] = Field(None, gt=0)
    priceRent: Optional[float] = Field(None, gt=0)

    rooms: Optional[int] = Field(None, ge=0, le=50)
    bathrooms: Optional[int] = Field(None, ge=0, le=20)
    surfaceArea: Optional[float] = Field(None, gt=0)

    city: str = Field(..., min_length=2)
    address: str = Field(..., min_length=5)

    @validator('priceSale')
    def validate_price_sale(cls, v, values):
        contract_type = values.get('contractType')
        if contract_type in ['sale', 'both'] and v is None:
            raise ValueError('priceSale required for sale properties')
        return v

    @validator('priceRent')
    def validate_price_rent(cls, v, values):
        contract_type = values.get('contractType')
        if contract_type in ['rent', 'both'] and v is None:
            raise ValueError('priceRent required for rent properties')
        return v

    class Config:
        orm_mode = True

class PropertyCreate(PropertyBase):
    ownerContactId: str = Field(..., regex="^[a-zA-Z0-9]+$")
    buildingId: Optional[str] = None

class PropertyUpdate(BaseModel):
    title: Optional[str] = Field(None, min_length=5, max_length=200)
    priceSale: Optional[float] = Field(None, gt=0)
    status: Optional[PropertyStatus] = None
    # ... altri field opzionali

class PropertyResponse(PropertyBase):
    id: str
    code: str
    status: PropertyStatus
    createdAt: datetime
    updatedAt: datetime
```

**Usage in API Routes**:

```python
# ai_tools/app/routers/properties.py (NUOVO)
from fastapi import APIRouter, HTTPException
from app.schemas.property_schema import PropertyCreate, PropertyUpdate, PropertyResponse
from app.services.property_service import PropertyService

router = APIRouter(prefix="/properties", tags=["properties"])
service = PropertyService()

@router.post("/", response_model=PropertyResponse, status_code=201)
async def create_property(data: PropertyCreate):
    """Create new property with validation"""
    try:
        property = service.create(data.dict())
        return property
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.put("/{property_id}", response_model=PropertyResponse)
async def update_property(property_id: str, data: PropertyUpdate):
    """Update property with validation"""
    try:
        property = service.update(property_id, data.dict(exclude_unset=True))
        return property
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
```

**Update AI Tools**:

```python
# ai_tools/app/tools/db_query_tool.py (MODIFIED)
from app.schemas.property_schema import PropertyCreate

@tool
def create_property_tool(
    title: str,
    property_type: str,
    price: float,
    # ...
) -> str:
    """Create a new property listing"""

    # Build data dict
    data = {
        "title": title,
        "propertyType": property_type,
        "priceSale": price,
        # ...
    }

    try:
        # Validate with Pydantic
        validated_data = PropertyCreate(**data)

        # Create in database
        property = create_property(validated_data.dict())

        return f"‚úÖ Property created: {property.code}"

    except ValidationError as e:
        return f"‚ùå Validation failed: {e.errors()}"
```

#### Task List
- [ ] Creare Pydantic schemas per tutti i modelli
- [ ] Implementare custom validators
- [ ] Aggiornare AI tools per usare schemas
- [ ] Aggiornare scraping per usare schemas
- [ ] Unit tests per validation rules

**Deliverable**: Validation layer completo Python

---

### 2.3 Transaction Support (H2) - 1 giorno

#### Problema
- Frontend: Operazioni multiple non atomiche
- Rischio data inconsistency

#### Soluzione: Transaction Wrapper

**Frontend (Prisma)**:

```typescript
// services/base/TransactionService.ts
export class TransactionService {
  constructor(private prisma: PrismaClient) {}

  async executeInTransaction<T>(
    operation: (tx: PrismaClient) => Promise<T>
  ): Promise<T> {
    return this.prisma.$transaction(operation);
  }
}

// services/PropertyService.ts (USANDO TRANSACTIONS)
async createPropertyWithBuilding(
  propertyData: PropertyCreateDTO,
  buildingData?: BuildingCreateDTO
): Promise<Property> {
  return this.prisma.$transaction(async (tx) => {
    let buildingId = propertyData.buildingId;

    // Step 1: Create building se non esiste
    if (!buildingId && buildingData) {
      const building = await tx.building.create({
        data: buildingData
      });
      buildingId = building.id;
    }

    // Step 2: Create property
    const property = await tx.property.create({
      data: {
        ...propertyData,
        buildingId
      }
    });

    // Step 3: Create initial activity
    await tx.activity.create({
      data: {
        type: 'property_created',
        propertyId: property.id,
        date: new Date(),
        notes: 'Property listing created'
      }
    });

    // Step 4: Update building stats
    if (buildingId) {
      await this.recalculateBuildingStats(buildingId, tx);
    }

    return property;
  });
}
```

**Backend (SQLAlchemy)**:

```python
# ai_tools/app/services/base_service.py
from contextlib import contextmanager

class BaseService:
    @contextmanager
    def transaction(self):
        """Context manager for transactions"""
        session = SessionLocal()
        try:
            yield session
            session.commit()
        except Exception as e:
            session.rollback()
            raise e
        finally:
            session.close()

    def execute_in_transaction(self, operation):
        """Execute operation in transaction"""
        with self.transaction() as session:
            return operation(session)

# ai_tools/app/services/property_service.py
class PropertyService(BaseService):
    def create_property_with_activity(self, property_data, activity_data):
        """Create property + initial activity atomically"""

        def operation(session):
            # Create property
            property = Property(**property_data)
            session.add(property)
            session.flush()  # Get ID without committing

            # Create activity
            activity = Activity(
                **activity_data,
                propertyId=property.id
            )
            session.add(activity)

            return property

        return self.execute_in_transaction(operation)
```

#### Task List
- [ ] Implementare TransactionService
- [ ] Refactorare operazioni complesse con transactions
- [ ] Aggiungere retry logic per deadlocks
- [ ] Unit tests per transaction rollback

**Deliverable**: Transaction support completo

---

### 2.4 Summary Phase 2

**Durata**: 5 giorni
**Effort**: 40 ore

**Deliverables**:
- ‚úÖ Service layer con 7 services
- ‚úÖ Validation layer Pydantic completo
- ‚úÖ Transaction support
- ‚úÖ API routes refactored
- ‚úÖ Unit tests per ogni service

**Success Metrics**:
- [ ] 100% API routes usano services
- [ ] 100% validazione su write operations
- [ ] 0 operazioni multi-step senza transaction
- [ ] Test coverage >80% su services

---

## üèóÔ∏è PHASE 3: REPOSITORY PATTERN & CACHING (Week 3)

**Obiettivo**: Astrazione completa data access + performance optimization
**Durata**: 5 giorni
**Effort**: 40 ore

### 3.1 Repository Pattern (M3) - 3 giorni

#### Soluzione: Repository Layer

```typescript
// repositories/base/IRepository.ts
export interface IRepository<T> {
  findById(id: string): Promise<T | null>;
  findMany(filters?: any): Promise<T[]>;
  create(data: any): Promise<T>;
  update(id: string, data: any): Promise<T>;
  delete(id: string): Promise<boolean>;
  count(filters?: any): Promise<number>;
}

// repositories/PropertyRepository.ts
export class PropertyRepository implements IRepository<Property> {
  constructor(private prisma: PrismaClient) {}

  async findById(id: string): Promise<Property | null> {
    return this.prisma.property.findUnique({
      where: { id },
      include: { owner: true, building: true }
    });
  }

  async findAvailableByCity(city: string): Promise<Property[]> {
    return this.prisma.property.findMany({
      where: {
        city,
        status: 'available'
      },
      orderBy: { urgencyScore: 'desc' }
    });
  }

  async findWithinRadius(
    lat: number,
    lng: number,
    radiusKm: number
  ): Promise<Property[]> {
    // Complex geo query
    const properties = await this.prisma.$queryRaw`
      SELECT *
      FROM properties
      WHERE (6371 * acos(
        cos(radians(${lat})) * cos(radians(latitude)) *
        cos(radians(longitude) - radians(${lng})) +
        sin(radians(${lat})) * sin(radians(latitude))
      )) <= ${radiusKm}
    `;

    return properties;
  }
}
```

**Service usa Repository**:

```typescript
// services/PropertyService.ts (REFACTORED)
export class PropertyService extends BaseService {
  constructor(
    prisma: PrismaClient,
    private propertyRepo: PropertyRepository
  ) {
    super(prisma);
  }

  async findAvailableProperties(filters: PropertyFilters) {
    // Use repository invece di Prisma diretto
    if (filters.city) {
      return this.propertyRepo.findAvailableByCity(filters.city);
    }

    if (filters.latitude && filters.longitude && filters.radius) {
      return this.propertyRepo.findWithinRadius(
        filters.latitude,
        filters.longitude,
        filters.radius
      );
    }

    return this.propertyRepo.findMany(this.buildFilters(filters));
  }
}
```

#### Task List
- [ ] Creare IRepository interface
- [ ] Implementare repository per ogni model (7 repos)
- [ ] Refactorare services per usare repositories
- [ ] Complex query methods in repositories
- [ ] Unit tests con mock repositories

**Deliverable**: Repository layer completo

---

### 3.2 Caching Layer (M1) - 2 giorni

#### Soluzione: Redis + In-Memory Cache

**Architecture**:
```
Request ‚Üí Service ‚Üí Cache Check ‚Üí Repository ‚Üí Database
                        ‚Üì Hit
                    Return Cached
```

**Implementation**:

```typescript
// cache/CacheService.ts
import Redis from 'ioredis';

export class CacheService {
  private redis: Redis;
  private memoryCache: Map<string, { data: any, expiry: number }>;

  constructor() {
    this.redis = new Redis(process.env.REDIS_URL);
    this.memoryCache = new Map();
  }

  async get<T>(key: string): Promise<T | null> {
    // Try memory cache first
    const memCached = this.memoryCache.get(key);
    if (memCached && memCached.expiry > Date.now()) {
      return memCached.data;
    }

    // Try Redis
    const redisCached = await this.redis.get(key);
    if (redisCached) {
      const data = JSON.parse(redisCached);

      // Store in memory cache
      this.memoryCache.set(key, {
        data,
        expiry: Date.now() + 60000 // 1 min
      });

      return data;
    }

    return null;
  }

  async set(key: string, value: any, ttlSeconds: number = 3600) {
    // Set in Redis
    await this.redis.setex(key, ttlSeconds, JSON.stringify(value));

    // Set in memory cache
    this.memoryCache.set(key, {
      data: value,
      expiry: Date.now() + Math.min(ttlSeconds, 60) * 1000
    });
  }

  async invalidate(pattern: string) {
    // Invalidate Redis keys
    const keys = await this.redis.keys(pattern);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }

    // Invalidate memory cache
    for (const [key] of this.memoryCache) {
      if (this.matchPattern(key, pattern)) {
        this.memoryCache.delete(key);
      }
    }
  }

  private matchPattern(key: string, pattern: string): boolean {
    const regex = new RegExp(pattern.replace('*', '.*'));
    return regex.test(key);
  }
}
```

**Repository con Cache**:

```typescript
// repositories/PropertyRepository.ts (WITH CACHE)
export class PropertyRepository {
  constructor(
    private prisma: PrismaClient,
    private cache: CacheService
  ) {}

  async findById(id: string): Promise<Property | null> {
    const cacheKey = `property:${id}`;

    // Check cache
    const cached = await this.cache.get<Property>(cacheKey);
    if (cached) {
      return cached;
    }

    // Query database
    const property = await this.prisma.property.findUnique({
      where: { id },
      include: { owner: true, building: true }
    });

    // Cache result
    if (property) {
      await this.cache.set(cacheKey, property, 3600); // 1 hour
    }

    return property;
  }

  async update(id: string, data: any): Promise<Property> {
    // Update database
    const property = await this.prisma.property.update({
      where: { id },
      data
    });

    // Invalidate cache
    await this.cache.invalidate(`property:${id}`);
    await this.cache.invalidate(`property:list:*`);

    return property;
  }
}
```

**Smart Cache Strategies**:

```typescript
// cache/strategies.ts
export const CacheStrategies = {
  // Never change data - cache forever
  STATIC: { ttl: 86400 * 30 }, // 30 days

  // Lookup tables - long cache
  LOOKUP: { ttl: 3600 * 24 }, // 24 hours

  // Business data - medium cache
  ENTITY: { ttl: 3600 }, // 1 hour

  // Aggregations - short cache
  STATS: { ttl: 300 }, // 5 minutes

  // Real-time - very short cache
  REALTIME: { ttl: 30 } // 30 seconds
};

// Usage
await cache.set('tags:all', tags, CacheStrategies.LOOKUP.ttl);
await cache.set('dashboard:stats', stats, CacheStrategies.STATS.ttl);
```

#### Task List
- [ ] Setup Redis (docker-compose)
- [ ] Implementare CacheService
- [ ] Aggiungere cache a repositories
- [ ] Cache invalidation strategy
- [ ] Cache warming scripts
- [ ] Monitoring cache hit rate

**Deliverable**: Caching layer funzionante

---

### 3.3 Summary Phase 3

**Durata**: 5 giorni
**Effort**: 40 ore

**Deliverables**:
- ‚úÖ Repository pattern (7 repositories)
- ‚úÖ Caching layer (Redis + memory)
- ‚úÖ Cache invalidation strategy
- ‚úÖ Performance monitoring

**Success Metrics**:
- [ ] 100% data access via repositories
- [ ] Cache hit rate >70%
- [ ] API response time -60%
- [ ] Database query load -50%

---

## üö¢ PHASE 4: MIGRATION TO POSTGRESQL & FINAL OPTIMIZATIONS (Week 4+)

**Obiettivo**: Production-grade database + advanced features
**Durata**: 1-2 settimane
**Effort**: 80 ore

### 4.1 Migrazione a PostgreSQL (L2) - 1 settimana

#### Motivazioni
- SQLite limitations: No concurrent writes, limited full-text search
- PostgreSQL features: JSONB, full-text search, advanced indexing
- Scalability: Ready for production load

#### Migration Plan

**Step 1: Setup PostgreSQL**
```bash
# docker-compose.yml
services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: crm_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: crm_immobiliare
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
```

**Step 2: Update Schema**
```prisma
// schema.prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

// Enable PostgreSQL-specific features
model Property {
  // ... existing fields

  // Full-text search
  searchVector Unsupported("tsvector")?

  @@index([searchVector], type: Gin)
}
```

**Step 3: Data Migration Script**
```typescript
// scripts/migrate-to-postgresql.ts
async function migrateToPostgreSQL() {
  const sqlite = new PrismaClient({
    datasources: { db: { url: 'file:./dev.db' } }
  });

  const postgres = new PrismaClient({
    datasources: { db: { url: process.env.POSTGRES_URL } }
  });

  // Migrate in batches
  const batchSize = 100;

  // 1. Migrate UserProfile
  const userProfile = await sqlite.userProfile.findFirst();
  await postgres.userProfile.create({ data: userProfile });

  // 2. Migrate Contacts
  let skip = 0;
  while (true) {
    const contacts = await sqlite.contact.findMany({
      skip,
      take: batchSize
    });

    if (contacts.length === 0) break;

    await postgres.contact.createMany({ data: contacts });
    skip += batchSize;
    console.log(`Migrated ${skip} contacts...`);
  }

  // 3. Migrate Buildings
  // 4. Migrate Properties
  // 5. Migrate Requests
  // 6. Migrate Matches
  // 7. Migrate Activities
  // ... etc
}
```

#### Task List
- [ ] Setup PostgreSQL in docker-compose
- [ ] Update Prisma schema per PostgreSQL
- [ ] Creare migration script
- [ ] Test migration in staging
- [ ] Execute migration in production
- [ ] Update backup scripts per PostgreSQL

**Deliverable**: PostgreSQL production-ready

---

### 4.2 Full-Text Search (L1) - 3 giorni

#### Implementation

```prisma
// schema.prisma (PostgreSQL)
model Property {
  // ...existing fields

  // Full-text search vector
  searchVector Unsupported("tsvector")?

  @@index([searchVector], map: "property_search_idx", type: Gin)
}

model Contact {
  // ...existing fields

  searchVector Unsupported("tsvector")?

  @@index([searchVector], map: "contact_search_idx", type: Gin)
}
```

```sql
-- Migration: Add search vectors
CREATE OR REPLACE FUNCTION property_search_vector_update() RETURNS trigger AS $$
BEGIN
  NEW.searchVector :=
    setweight(to_tsvector('italian', coalesce(NEW.title, '')), 'A') ||
    setweight(to_tsvector('italian', coalesce(NEW.description, '')), 'B') ||
    setweight(to_tsvector('italian', coalesce(NEW.address, '')), 'C') ||
    setweight(to_tsvector('italian', coalesce(NEW.city, '')), 'C');
  RETURN NEW;
END
$$ LANGUAGE plpgsql;

CREATE TRIGGER property_search_vector_update
  BEFORE INSERT OR UPDATE ON properties
  FOR EACH ROW
  EXECUTE FUNCTION property_search_vector_update();
```

```typescript
// repositories/PropertyRepository.ts
async fullTextSearch(query: string, limit: number = 20): Promise<Property[]> {
  return this.prisma.$queryRaw`
    SELECT *,
           ts_rank(searchVector, plainto_tsquery('italian', ${query})) as rank
    FROM properties
    WHERE searchVector @@ plainto_tsquery('italian', ${query})
    ORDER BY rank DESC
    LIMIT ${limit}
  `;
}
```

**Deliverable**: Full-text search funzionante

---

### 4.3 Soft Delete Pattern (M4) - 1 giorno

```prisma
// schema.prisma
model Property {
  // ...existing fields
  deletedAt DateTime?
  deletedBy String?

  @@index([deletedAt])
}

// Repeat for all models
```

```typescript
// repositories/base/SoftDeleteRepository.ts
export abstract class SoftDeleteRepository<T> extends BaseRepository<T> {
  async softDelete(id: string, deletedBy: string): Promise<T> {
    return this.prisma[this.modelName].update({
      where: { id },
      data: {
        deletedAt: new Date(),
        deletedBy
      }
    });
  }

  async restore(id: string): Promise<T> {
    return this.prisma[this.modelName].update({
      where: { id },
      data: {
        deletedAt: null,
        deletedBy: null
      }
    });
  }

  async findMany(filters?: any): Promise<T[]> {
    return this.prisma[this.modelName].findMany({
      where: {
        ...filters,
        deletedAt: null // Exclude deleted by default
      }
    });
  }

  async findManyWithDeleted(filters?: any): Promise<T[]> {
    return this.prisma[this.modelName].findMany({
      where: filters
    });
  }
}
```

**Deliverable**: Soft delete implementato

---

### 4.4 Database Monitoring (M2) - 1 giorno

```typescript
// monitoring/DatabaseMonitor.ts
export class DatabaseMonitor {
  async getSlowQueries(minDurationMs: number = 1000): Promise<Query[]> {
    // PostgreSQL specific
    return this.prisma.$queryRaw`
      SELECT
        query,
        calls,
        total_time,
        mean_time,
        max_time
      FROM pg_stat_statements
      WHERE mean_time > ${minDurationMs}
      ORDER BY mean_time DESC
      LIMIT 20
    `;
  }

  async getConnectionPoolStats() {
    const [result] = await this.prisma.$queryRaw`
      SELECT
        count(*) FILTER (WHERE state = 'active') as active,
        count(*) FILTER (WHERE state = 'idle') as idle,
        count(*) as total
      FROM pg_stat_activity
      WHERE datname = current_database()
    `;

    return result;
  }

  async getTableSizes() {
    return this.prisma.$queryRaw`
      SELECT
        schemaname,
        tablename,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
      FROM pg_tables
      WHERE schemaname = 'public'
      ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
    `;
  }
}
```

**Deliverable**: Monitoring dashboard

---

### 4.5 Summary Phase 4

**Durata**: 2 settimane
**Effort**: 80 ore

**Deliverables**:
- ‚úÖ Migrazione a PostgreSQL completa
- ‚úÖ Full-text search funzionante
- ‚úÖ Soft delete implementato
- ‚úÖ Database monitoring dashboard

**Success Metrics**:
- [ ] Zero downtime migration
- [ ] Search results <100ms
- [ ] 100% data recovery capability
- [ ] Full visibility su slow queries

---

## üìà SUCCESS METRICS & KPIs

### Code Quality Metrics

| Metric | Before | After | Target |
|--------|--------|-------|--------|
| Files accessing DB directly | 38 | 0 | 0 |
| Duplicated query logic | High | None | 0% |
| Test coverage (services) | 0% | >80% | >80% |
| Validation coverage | 40% | 100% | 100% |
| Schema sync Prisma‚ÜîSQLAlchemy | 88% | 100% | 100% |

### Performance Metrics

| Metric | Before | After | Target |
|--------|--------|-------|--------|
| Average API response time | 200ms | <80ms | <100ms |
| Cache hit rate | 0% | >70% | >70% |
| Database query load | Baseline | -50% | -50% |
| Dashboard load time | 2s | <500ms | <800ms |

### Reliability Metrics

| Metric | Before | After | Target |
|--------|--------|-------|--------|
| Schema drift incidents/month | ~2 | 0 | 0 |
| Deployment failures | ~30% | <5% | <5% |
| Data loss incidents | Risk High | Risk Zero | 0 |
| Transaction failures | Unknown | <0.1% | <0.1% |

### Maintainability Metrics

| Metric | Before | After | Target |
|--------|--------|-------|--------|
| Time to add new model | 2h | 30min | <1h |
| Migration time | N/A | <5min | <10min |
| Onboarding time (new dev) | 3 days | 1 day | <2 days |

---

## üìÖ TIMELINE & MILESTONES

```
Week 1: CRITICAL FIXES
‚îú‚îÄ Day 1-2: Migrations + Backup System
‚îú‚îÄ Day 3: DATABASE_URL Unification
‚îî‚îÄ Day 4-5: Prisma‚ÜîSQLAlchemy Sync

Week 2: SERVICE LAYER
‚îú‚îÄ Day 1-2: Service Layer Implementation
‚îú‚îÄ Day 3: Validation Layer (Pydantic)
‚îî‚îÄ Day 4-5: Transaction Support + Refactoring

Week 3: OPTIMIZATION
‚îú‚îÄ Day 1-3: Repository Pattern
‚îî‚îÄ Day 4-5: Caching Layer + Testing

Week 4+: PRODUCTION READY
‚îú‚îÄ Week 4: PostgreSQL Migration
‚îú‚îÄ Day +1-3: Full-Text Search
‚îú‚îÄ Day +4: Soft Delete
‚îî‚îÄ Day +5: Monitoring & Final Tests
```

**Checkpoint Meetings**:
- Fine Week 1: Review critical fixes
- Fine Week 2: Review service layer
- Fine Week 3: Performance tests
- Fine Week 4: Production readiness review

---

## üõ†Ô∏è TOOLS & TECHNOLOGIES

### Development Tools
- **Prisma**: ORM TypeScript
- **SQLAlchemy**: ORM Python
- **Pydantic**: Python validation
- **Zod**: TypeScript validation
- **Redis**: Caching layer
- **PostgreSQL**: Production database

### Testing Tools
- **Vitest**: Unit tests TypeScript
- **Pytest**: Unit tests Python
- **Prisma Studio**: Database GUI
- **pgAdmin**: PostgreSQL management

### Monitoring Tools
- **Prisma Query Logging**: Development
- **pg_stat_statements**: Production queries
- **Redis Monitor**: Cache statistics

---

## üí∞ COST ESTIMATION

### Development Cost
| Phase | Days | Hours | Cost (@‚Ç¨80/h) |
|-------|------|-------|---------------|
| Phase 1: Critical | 5 | 40 | ‚Ç¨3,200 |
| Phase 2: Service Layer | 5 | 40 | ‚Ç¨3,200 |
| Phase 3: Optimization | 5 | 40 | ‚Ç¨3,200 |
| Phase 4: PostgreSQL | 10 | 80 | ‚Ç¨6,400 |
| **TOTAL** | **25** | **200** | **‚Ç¨16,000** |

### Infrastructure Cost (Annual)
| Service | Cost/month | Cost/year |
|---------|-----------|-----------|
| PostgreSQL (Managed) | ‚Ç¨50 | ‚Ç¨600 |
| Redis (Managed) | ‚Ç¨30 | ‚Ç¨360 |
| Backup Storage (100GB) | ‚Ç¨10 | ‚Ç¨120 |
| **TOTAL** | **‚Ç¨90** | **‚Ç¨1,080** |

### ROI Analysis

**Savings from Refactoring**:
- Maintenance time: -70% = ~‚Ç¨8,000/year
- Bug fixes: -80% = ~‚Ç¨5,000/year
- Deployment issues: -90% = ~‚Ç¨3,000/year

**Total Annual Savings**: ‚Ç¨16,000
**Payback Period**: 1 anno
**5-Year ROI**: 400%

---

## üö¶ RISKS & MITIGATION

### High Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Data loss durante migration | Medium | Critical | Backup completi + rollback plan |
| Breaking changes in API | High | High | Backward compatibility + versioning |
| Performance degradation | Low | Medium | Load testing + monitoring |
| Schema drift post-refactoring | Medium | High | Automated sync checks in CI |

### Mitigation Strategies

**1. Data Loss Prevention**
- Triple backup strategy (before/during/after)
- Test migration in staging first
- Rollback scripts ready
- Data validation post-migration

**2. Breaking Changes**
- Maintain old API endpoints during transition
- Semantic versioning
- Deprecation warnings
- Migration guides for consumers

**3. Performance**
- Load testing before/after each phase
- Monitoring dashboards
- Performance budgets
- Rollback on regression

**4. Schema Sync**
- Automated validation in CI/CD
- Block deployments on mismatch
- Auto-generation from Prisma
- Weekly sync checks

---

## üìö DOCUMENTATION DELIVERABLES

### Technical Documentation
- [ ] `DATABASE_ARCHITECTURE.md` - Complete architecture overview
- [ ] `MIGRATIONS_GUIDE.md` - Migration workflow
- [ ] `BACKUP_RECOVERY.md` - Backup & recovery procedures
- [ ] `SERVICE_LAYER_DOCS.md` - Service layer patterns
- [ ] `REPOSITORY_PATTERN.md` - Repository usage guide
- [ ] `CACHING_STRATEGY.md` - Caching best practices
- [ ] `POSTGRESQL_MIGRATION.md` - PostgreSQL migration guide

### API Documentation
- [ ] OpenAPI/Swagger specs updated
- [ ] Service method documentation
- [ ] Repository method documentation
- [ ] DTO/Schema documentation

### Operational Documentation
- [ ] Deployment procedures updated
- [ ] Monitoring setup guide
- [ ] Troubleshooting guide
- [ ] Performance tuning guide

---

## ‚úÖ ACCEPTANCE CRITERIA

### Phase 1 (Critical) - DONE WHEN:
- [x] Prisma migrations can be applied without errors
- [x] Automatic daily backups running
- [x] Single DATABASE_URL config works for all services
- [x] Prisma ‚Üî SQLAlchemy 100% in sync
- [x] CI pipeline validates all above

### Phase 2 (Service Layer) - DONE WHEN:
- [x] All 7 core services implemented
- [x] 100% API routes use services (not direct Prisma)
- [x] Pydantic validation on all Python write operations
- [x] Complex operations use transactions
- [x] Test coverage >80%

### Phase 3 (Optimization) - DONE WHEN:
- [x] Repository pattern for all models
- [x] Redis caching operational
- [x] Cache hit rate >70%
- [x] API response time improved by 60%
- [x] No direct database access in business logic

### Phase 4 (Production) - DONE WHEN:
- [x] PostgreSQL migration successful
- [x] Zero data loss validated
- [x] Full-text search operational
- [x] Soft delete implemented
- [x] Monitoring dashboard live
- [x] Load testing passed

---

## üéØ NEXT STEPS

### Immediate Actions (This Week)
1. Review e approval del piano
2. Setup development environment
3. Create feature branch `feature/database-refactoring`
4. Iniziare Phase 1 - Critical Fixes

### Decision Points
- [ ] Approval budget (‚Ç¨16,000)
- [ ] Approval timeline (4 settimane)
- [ ] PostgreSQL vs stay SQLite decision
- [ ] Redis hosting strategy (self-hosted vs managed)

### Pre-Work Required
- [ ] Backup completo database attuale
- [ ] Setup staging environment
- [ ] Access credentials per PostgreSQL/Redis
- [ ] CI/CD pipeline setup

---

## üìû CONTATTI & SUPPORT

**Project Owner**: [Nome]
**Lead Developer**: [Nome]
**Database Architect**: [Nome]

**Communication Channels**:
- Daily standup: 9:00 AM
- Weekly review: Friday 3:00 PM
- Slack channel: #database-refactoring
- Email: team@crm-immobiliare.com

---

**Document Version**: 1.0
**Last Updated**: 2025-11-10
**Next Review**: 2025-11-17
**Status**: ‚úÖ Ready for Review

---

## üéì APPENDIX: LEARNING RESOURCES

### Prisma
- [Prisma Migrations Guide](https://www.prisma.io/docs/concepts/components/prisma-migrate)
- [Prisma Best Practices](https://www.prisma.io/docs/guides/performance-and-optimization)

### Repository Pattern
- [Martin Fowler - Repository Pattern](https://martinfowler.com/eaaCatalog/repository.html)

### PostgreSQL
- [PostgreSQL Full-Text Search](https://www.postgresql.org/docs/current/textsearch.html)
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization)

---

**END OF DOCUMENT**
